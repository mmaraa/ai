{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Own Data - Vector database\n",
    "\n",
    "This notebook contains an example how to use ready vector database as own data with Azure Open AI Services. In this example our vector database is Azure AI Search that indexes all of our data. Vector database is the most common scenario to achieve better search results based on your own data. It is required that your Vector database supports your data types that you index to it. \n",
    "\n",
    "My data example here includes all published results (until 3rd of March 2024) for Finnish Figure Skating association's Synchronized skating competitions from the season 2023-2024. More information about results you can find from [https://www.figureskatingresults.fi/](https://www.figureskatingresults.fi/).\n",
    "\n",
    "## Pre-requirements \n",
    "\n",
    "- Create OpenAI service to Azure and deploy at least one model. Fill your own *config.jsonc* file. You can find an example file from *example-config.jsonc*. \n",
    "- Azure Blob container that contains all necessary files in a single folder\n",
    "- Azure AI Search service that has already indexed those files using embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet openai jsonc-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration and initliaze client\n",
    "from openai import AzureOpenAI\n",
    "from jsonc_parser.parser import JsoncParser\n",
    "\n",
    "config = JsoncParser.parse_file('config.jsonc')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=config['azure_oai_api_version'],\n",
    "    azure_endpoint=config['azure_oai_endpoint'],\n",
    "    api_key=config['azure_oai_key']\n",
    ")\n",
    "gpt_model_name=config['azure_oai_gpt_model_name']\n",
    "embedding_model_name=config['azure_oai_embedding_model_name']\n",
    "ai_search_endpoint=config['azure_ai_search_endpoint']\n",
    "ai_search_key=config['azure_ai_search_key']\n",
    "ai_index_name=config['azure_ai_index_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use vector database with keyword based search\n",
    "\n",
    "Connect to source data with keyword based search (does not use embeddings).\n",
    "\n",
    "Because the source data is quite tabular without closer information about teams, this is not the best solutions for the search options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prompt\n",
    "message_text = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":\"You are an AI assistant that helps people find information about Finnish Figure Skating Associations Synchronized Skating results on season 2023-2024. There are azure-search based data source provided with that data.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Which team has got most of points in the category of Seniors?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Start client towards the AI\n",
    "response = client.chat.completions.create(\n",
    "    model=gpt_model_name,\n",
    "    messages=message_text,\n",
    "    max_tokens=1000,\n",
    "    extra_body={\n",
    "        \"data_sources\": [\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": ai_search_endpoint,\n",
    "                    \"index_name\": ai_index_name,\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": ai_search_key\n",
    "                    },\n",
    "                    \"query_type\": \"simple\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print content\n",
    "print(\"System message: \", message_text[0]['content'])\n",
    "print(\"User message: \", message_text[1]['content'])\n",
    "print(\"Response: \",response.choices[0].message.content)\n",
    "print(\"Input tokens: \", response.usage.prompt_tokens)\n",
    "print(\"Output tokens: \", response.usage.total_tokens-response.usage.prompt_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use vector database with vector based search\n",
    "\n",
    "Connect to Vector database with vector based search. \n",
    "\n",
    "While using vector based search, we find correct answers from our data. When comparing to the keyword based search that did not find anything, this maps the question's embedding towards the vector database and by using k-nearest neighbor (KNN) -algorithm finds the closest result and prints out it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prompt\n",
    "message_text = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":\"You are an AI assistant that helps people find information about Finnish Figure Skating Associations Synchronized Skating results on season 2023-2024. There are azure-search based data source provided with that data.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Which team has got most of points in the category of Seniors?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Start client towards the AI\n",
    "response = client.chat.completions.create(\n",
    "    model=gpt_model_name,\n",
    "    messages=message_text,\n",
    "    max_tokens=1000,\n",
    "    extra_body={\n",
    "        \"data_sources\": [\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": ai_search_endpoint,\n",
    "                    \"index_name\": ai_index_name,\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": ai_search_key\n",
    "                    },\n",
    "                    \"embedding_dependency\": {\n",
    "                        \"type\": \"deployment_name\",\n",
    "                        \"deployment_name\": embedding_model_name\n",
    "                    },\n",
    "                    \"query_type\": \"vector\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print content\n",
    "print(\"System message: \", message_text[0]['content'])\n",
    "print(\"User message: \", message_text[1]['content'])\n",
    "print(\"Response: \",response.choices[0].message.content)\n",
    "print(\"Input tokens: \", response.usage.prompt_tokens)\n",
    "print(\"Output tokens: \", response.usage.total_tokens-response.usage.prompt_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using together or add semantic ranking support\n",
    "\n",
    "You can combine these two elements by choosing *vector_simple_hybrid* as a query type. Because the source data is kind of and mostly table structured PDF in my case and the keyword search did not find anything, this is not going to find anything either. If your source data is prose-structured text, you can turn on semantic ranging support by setting query type as *vector_semantic_hybrid* or *semantic*. Semantic ranking understands the context of the question and can make better answers with the right context. Keep in mind that semantic ranking is not always necessary.\n",
    "\n",
    "### Pricing considerations\n",
    "\n",
    "When you enable keyword+vector based query or semantic type of query, it will increase your cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
